{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9693307,"sourceType":"datasetVersion","datasetId":5926400},{"sourceId":9695052,"sourceType":"datasetVersion","datasetId":5927748},{"sourceId":202697797,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-22T18:19:43.121630Z","iopub.execute_input":"2024-10-22T18:19:43.122014Z","iopub.status.idle":"2024-10-22T18:19:43.126692Z","shell.execute_reply.started":"2024-10-22T18:19:43.121979Z","shell.execute_reply":"2024-10-22T18:19:43.125546Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/model-data/Model_Data.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-22T18:19:43.128649Z","iopub.execute_input":"2024-10-22T18:19:43.129023Z","iopub.status.idle":"2024-10-22T18:19:43.189849Z","shell.execute_reply.started":"2024-10-22T18:19:43.128958Z","shell.execute_reply":"2024-10-22T18:19:43.188861Z"}},"outputs":[],"execution_count":98},{"cell_type":"code","source":"X = df.drop(columns='label')\n\ny = df['label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-22T18:19:43.190959Z","iopub.execute_input":"2024-10-22T18:19:43.191244Z","iopub.status.idle":"2024-10-22T18:19:43.200547Z","shell.execute_reply.started":"2024-10-22T18:19:43.191212Z","shell.execute_reply":"2024-10-22T18:19:43.199619Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"# SPLIT DU Lieu\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-22T18:19:43.202906Z","iopub.execute_input":"2024-10-22T18:19:43.203515Z","iopub.status.idle":"2024-10-22T18:19:43.211729Z","shell.execute_reply.started":"2024-10-22T18:19:43.203466Z","shell.execute_reply":"2024-10-22T18:19:43.210742Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report, make_scorer, roc_auc_score\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.over_sampling import SMOTE\n\n# Define the pipeline\npipeline = Pipeline([\n    ('smoteenn', SMOTEENN(smote=SMOTE(k_neighbors=5))),  \n    ('scaler', MinMaxScaler()), \n    ('classification', LogisticRegression(solver=\"liblinear\", max_iter=5000)) \n])\n\n# Define the parameter grid for Logistic Regression\nparam_grid = {\n    'classification__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],  \n    'classification__penalty': ['l1', 'l2'], \n    'classification__class_weight': ['balanced', None],  # Dealing with imbalance\n}\n\n# Define StratifiedKFold cross-validation strategy\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Use ROC AUC as the scoring metric\nscoring = make_scorer(roc_auc_score)\n\n# RandomizedSearchCV for hyperparameter tuning\nrandom_search = RandomizedSearchCV(\n    pipeline, \n    param_grid, \n    n_iter=28,  # Number of random parameter settings sampled\n    cv=cv,  # Cross-validation strategy\n    n_jobs=-1,  # Use all processors\n    verbose=1,  # Output process details\n    random_state=42,  # For reproducibility\n    scoring=scoring  # ROC AUC as evaluation metric\n)\n\n# Fit the model using RandomizedSearchCV\nrandom_search.fit(X_train, y_train)\n\n# Display best hyperparameters and accuracy\nprint(\"Tuned hyperparameters: (best parameters)\", random_search.best_params_)\nprint(\"\\033[1m\" + \"Best ROC AUC:\", random_search.best_score_)\n\n# Predict on test set\ny_pred = random_search.predict(X_test)\n\n# Print classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-22T18:19:43.212952Z","iopub.execute_input":"2024-10-22T18:19:43.213332Z","iopub.status.idle":"2024-10-22T18:20:25.945407Z","shell.execute_reply.started":"2024-10-22T18:19:43.213293Z","shell.execute_reply":"2024-10-22T18:20:25.944409Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 28 candidates, totalling 140 fits\nTuned hyperparameters: (best parameters) {'classification__penalty': 'l1', 'classification__class_weight': 'balanced', 'classification__C': 0.1}\n\u001b[1mBest ROC AUC: 0.7601631925959261\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.91      0.81      0.86      1745\n           1       0.54      0.73      0.62       539\n\n    accuracy                           0.79      2284\n   macro avg       0.73      0.77      0.74      2284\nweighted avg       0.82      0.79      0.80      2284\n\n","output_type":"stream"}],"execution_count":101},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.over_sampling import SMOTE\n\npipeline = Pipeline([\n    ('smoteenn', SMOTEENN(smote=SMOTE(k_neighbors=5))),  \n    ('scaler', MinMaxScaler()), \n    ('classification', LogisticRegression(solver=\"liblinear\", max_iter=5000)) \n])\n\n\nparam_grid = {\n    'classification__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],  \n    'classification__penalty': ['l1', 'l2'], \n    'classification__class_weight': ['balanced', None],  # Dealing with imbalance\n}\n\n# Use StratifiedKFold to maintain class distribution in folds\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# GridSearchCV for hyperparameter tuning\ngrid_search = GridSearchCV(pipeline, param_grid, cv=cv, n_jobs=-1, verbose=1)\ngrid_search.fit(X_train, y_train)\n\n# Display best hyperparameters and accuracy\nprint(\"Tuned hyperparameters: (best parameters)\", grid_search.best_params_)\nprint(\"\\033[1m\" + \"Accuracy:\", grid_search.best_score_)\n\n# Predict on test set\ny_pred = grid_search.predict(X_test)\n\n# Print classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-22T18:20:25.946494Z","iopub.execute_input":"2024-10-22T18:20:25.946882Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 28 candidates, totalling 140 fits\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}